## ML Reviews Analyzer

### Descripci√≥n
Sistema completo de an√°lisis de reviews de MercadoLibre con:
- **Backend**: API REST (FastAPI) con base de datos PostgreSQL
- **Frontend**: Aplicaci√≥n React con TypeScript y gr√°ficos interactivos
- **Scraping**: M√∫ltiples m√©todos (API oficial, API noindex, Playwright)
- **An√°lisis**: Sentimiento en espa√±ol, an√°lisis temporal, comparaci√≥n de marcas
- **Visualizaci√≥n**: Gr√°ficos temporales, distribuciones de ratings, an√°lisis de sentimiento

### Arquitectura
- `src/api/`: Cliente ML oficial y rate limiter
- `src/models/`: Modelos `Product` y `Review` con campos extendidos
- `src/services/`: Servicios de scraping, an√°lisis y procesamiento
- `src/web/app.py`: API REST con endpoints modernos
- `frontend/`: Aplicaci√≥n React con TypeScript y Recharts
- `docs/`: Documentaci√≥n t√©cnica y arquitectura

### Requisitos
- Python 3.11+ (o Docker)
- Node.js 18+ (para frontend)
- Playwright (para extractor de productos): `pip install playwright && playwright install`

### Setup local (venv)
```bash
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
cp .env.example .env
python -c "from src.models.database import init_db; init_db()"
python main.py
# Healthcheck
curl http://127.0.0.1:8000/health
```

### Variables de entorno
- `ML_OFFLINE_MODE` (True/False) ‚Äî por defecto False
- `ML_ACCESS_TOKEN` ‚Äî token OAuth para ML (opcional). Si no est√°, se usa endpoint noindex.
- `DATABASE_URL` ‚Äî por defecto `sqlite:///data/reviews.db`. En Docker usamos Postgres: `postgresql+psycopg2://mluser:mlpass@db:5432/mlreviews`

### Endpoints principales (API REST)

#### Endpoints modernos (recomendados)
- `GET /api/products` ‚Äî Lista todos los productos con filtros opcionales
- `GET /api/products/{id}` ‚Äî Detalles de un producto espec√≠fico
- `GET /api/products/{id}/reviews` ‚Äî Reviews de un producto (sin l√≠mite por defecto)
- `GET /api/products/{id}/reviews/stats` ‚Äî Estad√≠sticas de reviews de un producto
- `GET /api/reviews` ‚Äî Lista todas las reviews con filtros
- `GET /api/reviews/timeline` ‚Äî Datos temporales para gr√°ficos (√∫ltimos 365 d√≠as)
- `GET /api/reviews/stats` ‚Äî Estad√≠sticas globales de reviews

#### Endpoints legacy (compatibilidad)
- `GET /health` ‚Äî Health check
- `GET /api/search?q=...&limit=...` ‚Äî B√∫squeda de productos
- `GET /api/items/{id}` ‚Äî Producto por ID (legacy)
- `GET /api/items/{id}/reviews` ‚Äî Reviews de producto (legacy)

### Job batch (manual)
```bash
source venv/bin/activate
python -m src.services.batch_fetch --items MLA123,MLA456 --count 200 --page-size 50
```

### Scraper principal (API noindex)
# Ya no requiere instalaci√≥n de navegador - usa solo API noindex

Uso (una o varias URLs):
```bash
source venv/bin/activate
python -m src.services.scrape_final --url "https://.../p/MLA25265609#reviews" --url "https://.../p/MLA00000001#reviews" --count 150
# o usando archivo
python -m src.services.scrape_final --urls-file urls.txt --count 150
```

### Extractor de productos (Playwright)
```bash
source venv/bin/activate
python -m src.services.extract_product_simple                       # Lee desde urls.txt
python -m src.services.extract_product_simple "https://.../p/MLA25265609"  # URL espec√≠fica
```

### Analizador de sentimiento
```bash
source venv/bin/activate
python -m src.services.sentiment_analyzer                           # Todas las reviews sin an√°lisis
python -m src.services.sentiment_analyzer --from-date 2024-01-01   # Desde fecha espec√≠fica
python -m src.services.sentiment_analyzer --dry-run                 # Ver qu√© se procesar√≠a
```

### Frontend React
```bash
cd frontend
npm install
npm run dev
# Abrir http://localhost:5173
```

#### Caracter√≠sticas del Frontend
- **An√°lisis por Marca**: Visualizaci√≥n de estad√≠sticas por marca con gr√°ficos interactivos
- **Comparaci√≥n de Marcas**: Comparaci√≥n lado a lado de dos marcas
- **Gr√°ficos Temporales**: Evoluci√≥n de reviews, ratings y sentimiento en el tiempo
- **An√°lisis de Sentimiento**: Distribuci√≥n de sentimientos (positivo, negativo, neutral)
- **Distribuci√≥n de Ratings**: Visualizaci√≥n de estrellas con porcentajes correctos
- **Responsive Design**: Interfaz moderna y adaptativa

#### P√°ginas disponibles
- `/` - An√°lisis por marca (p√°gina principal)
- `/comparison` - Comparaci√≥n de marcas
- `/reviews` - Lista de todas las reviews
- `/products` - Lista de productos

### Docker (Postgres + scraper job opcional)
```bash
cp .env.example .env
docker compose up -d db
# Configurar DATABASE_URL a Postgres en tu .env o export (host local)
export DATABASE_URL=postgresql+psycopg2://mluser:mlpass@localhost:5432/mlreviews
source venv/bin/activate
pip install -r requirements.txt
python -c "from src.models.database import init_db; init_db(); print('ok')"
python main.py
# Healthcheck
curl http://127.0.0.1:8000/health
```

Job scraper en contenedor (lee `urls.txt` y trae 300 reviews c/u):
```bash
docker compose run --rm scraper
```

Scraper local (sin contenedor), por API noindex integrado en `src/services/scrape_final.py`:
```bash
export DATABASE_URL=postgresql+psycopg2://mluser:mlpass@localhost:5432/mlreviews
source venv/bin/activate
python -m src.services.scrape_final --urls-file urls.txt --count 150
```

### Scraper final: par√°metros y or√≠genes

El script `src/services/scrape_final.py` acepta par√°metros por CLI y usa variables de entorno para la conexi√≥n y modo de operaci√≥n.

- Par√°metros CLI:
  - `--url`: puede repetirse para pasar varias URLs a la vez
  - `--urls-file`: archivo con una URL por l√≠nea (ej. `urls.txt`)
  - `--count`: cantidad objetivo de reviews por producto (paginado por API noindex)

- Derivaci√≥n de datos desde la URL:
  - `item_id` y `site_id` se infieren del path (ej.: `/p/MLA25265603#reviews` ‚Üí `item_id=MLA25265603`, `site_id=MLA`)
  - Se consulta el endpoint paginado noindex: `/noindex/catalog/reviews/{objectId}/search?offset=...&limit=...`

- Variables de entorno relevantes:
  - `DATABASE_URL`: conexi√≥n a la base (en docker-compose: `postgresql+psycopg2://mluser:mlpass@db:5432/mlreviews`, en host: `...@localhost:5432/...`)
  - `ML_OFFLINE_MODE`: por defecto `False`
  - `ML_ACCESS_TOKEN`: opcional; si se setea, el proyecto puede usar el cliente oficial; si no, usa noindex

- Ejemplos:
  ```bash
  # Por archivo
  export DATABASE_URL=postgresql+psycopg2://mluser:mlpass@localhost:5432/mlreviews
  source venv/bin/activate
  python -m src.services.scrape_final --urls-file urls.txt --count 150

  # URLs sueltas
  python -m src.services.scrape_final \
    --url "https://www.mercadolibre.com.ar/p/MLA25265603#reviews" \
    --url "https://www.mercadolibre.com.ar/p/OTRA#reviews" \
    --count 120
  ```

### Online vs Offline
- Default actual: `ML_OFFLINE_MODE=False`. Si hay `ML_ACCESS_TOKEN`, se usa cliente oficial; si no, se usa endpoint noindex paginado (`/noindex/catalog/reviews/.../search?offset=...&limit=...`).
- DB por defecto en desarrollo: Postgres con docker-compose.

## Flujo de Trabajo Recomendado

### 1. Extracci√≥n de URLs
```bash
# Extraer URLs desde p√°ginas de listado
python3 src/services/extract_urls_simple.py "https://listado.mercadolibre.com.ar/aires-acondicionados" --max-pages 5 --output new_urls.txt

# Combinar con URLs existentes
python3 src/services/merge_urls.py --input new_urls.txt --existing urls.txt --output urls_final.txt --show-stats
```

### 2. Extracci√≥n de Datos
```bash
# Extraer informaci√≥n de productos
python3 src/services/extract_product_simple.py

# Extraer reviews
python3 src/services/batch_process_products.py --action reviews --min-reviews 1000
```

### 3. An√°lisis
```bash
# An√°lisis de sentimiento
python3 src/services/sentiment_analyzer.py

# Iniciar frontend para visualizaci√≥n
cd frontend && npm run dev
```

## Servicios de Procesamiento

### 1. Extractor de URLs (`extract_urls_simple.py`)
**Extrae URLs de productos desde p√°ginas de listado de MercadoLibre**
```bash
# Extraer URLs de una p√°gina de listado
python3 src/services/extract_urls_simple.py "https://listado.mercadolibre.com.ar/aires-acondicionados" --max-pages 5

# Extraer con delay personalizado
python3 src/services/extract_urls_simple.py "https://listado.mercadolibre.com.ar/aires-acondicionados" --max-pages 3 --delay 1.5 --output aires_urls.txt
```

### 2. Combinador de URLs (`merge_urls.py`)
**Combina URLs de diferentes fuentes y elimina duplicados**
```bash
# Combinar URLs extra√≠das con existentes
python3 src/services/merge_urls.py --input extracted_airs.txt --existing urls.txt --output urls_combined.txt

# Ver estad√≠sticas detalladas
python3 src/services/merge_urls.py --input new_urls.txt --existing old_urls.txt --output combined.txt --show-stats
```

### 3. Scraper Principal (`scrape_final.py`)
**Uso recomendado para ingesta masiva**
```bash
# Por archivo de URLs
python -m src.services.scrape_final --urls-file urls.txt --count 1000

# URLs individuales
python -m src.services.scrape_final --url "https://..." --count 500
```

### 4. Extractor de Productos (`extract_product_simple.py`)
**Para informaci√≥n detallada de productos (marca, modelo, caracter√≠sticas)**
```bash
# Desde archivo urls.txt
python -m src.services.extract_product_simple

# URL espec√≠fica
python -m src.services.extract_product_simple "https://..."
```

### 5. Procesamiento Batch (`batch_process_products.py`)
**Para procesar m√∫ltiples productos de forma eficiente**
```bash
# Scraping de reviews para todos los productos
python -m src.services.batch_process_products --action reviews --min-reviews 1000

# An√°lisis de sentimiento
python -m src.services.sentiment_analyzer
```

### 4. An√°lisis de Sentimiento
**Sistema mejorado para espa√±ol con palabras clave**
```bash
# Todas las reviews
python -m src.services.sentiment_analyzer

# Desde fecha espec√≠fica
python -m src.services.sentiment_analyzer --from-date 2024-01-01

# Modo dry-run
python -m src.services.sentiment_analyzer --dry-run
```

## Caracter√≠sticas T√©cnicas

### Modelo de Datos Extendido
- **Productos**: ID, t√≠tulo, precio, marca, modelo, caracter√≠sticas (JSONB), informaci√≥n adicional ML
- **Reviews**: Rating, contenido, fecha original, sentimiento, datos raw de la API
- **Relaciones**: Foreign keys optimizadas con √≠ndices

### An√°lisis de Sentimiento
- **Enfoque h√≠brido**: TextBlob + diccionario de palabras en espa√±ol
- **Clasificaci√≥n**: Positivo, negativo, neutral con score num√©rico
- **Procesamiento batch**: Eficiente para grandes vol√∫menes

### API REST Moderna
- **Endpoints RESTful**: Siguiendo convenciones est√°ndar
- **Filtros avanzados**: Por marca, fecha, rating, sentimiento
- **Paginaci√≥n**: Sin l√≠mites por defecto para m√°xima flexibilidad
- **CORS**: Configurado para desarrollo frontend

### Frontend React
- **TypeScript**: Tipado est√°tico para mejor desarrollo
- **Recharts**: Gr√°ficos interactivos y responsivos
- **Routing**: Navegaci√≥n entre p√°ginas de an√°lisis
- **Estado global**: Gesti√≥n eficiente de datos

## Estado Actual del Proyecto

‚úÖ **Completado**:
- Sistema de scraping completo (API noindex + Playwright)
- Base de datos PostgreSQL con modelos extendidos
- API REST moderna con endpoints completos
- Frontend React con an√°lisis visual
- An√°lisis de sentimiento en espa√±ol
- Gr√°ficos temporales y comparativos
- Correcci√≥n de fechas y c√°lculos de porcentajes

üîÑ **En progreso**:
- Optimizaci√≥n de performance para grandes vol√∫menes
- Mejoras en la UI/UX del frontend

üìã **Pr√≥ximos pasos sugeridos**:
- Autenticaci√≥n para panel admin
- Scheduler autom√°tico para actualizaciones peri√≥dicas
- Exportaci√≥n de datos (CSV, Excel)
- Alertas y notificaciones
- Dashboard ejecutivo con KPIs


