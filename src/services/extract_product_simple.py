#!/usr/bin/env python3
"""
Script simple para extraer informaciÃ³n de producto de MercadoLibre
VersiÃ³n simplificada con mejor manejo de errores
"""

import re
import time
import json
import os
from playwright.sync_api import sync_playwright
from datetime import datetime
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker
from src.models.database import Base
from src.models.product import Product


def load_env():
    """Carga variables de entorno desde .env"""
    try:
        from dotenv import load_dotenv
        load_dotenv()
    except ImportError:
        print("âš ï¸  python-dotenv no estÃ¡ instalado. Usando variables de entorno del sistema.")


def get_db_session():
    """Obtiene una sesiÃ³n de base de datos"""
    # Leer DATABASE_URL desde .env
    database_url = os.getenv('DATABASE_URL')
    if not database_url:
        # Fallback a PostgreSQL local
        database_url = "postgresql://postgres:postgres@localhost:5432/comment_ml_scraper"
    
    engine = create_engine(database_url)
    SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)
    return SessionLocal()


def save_product_to_db(product_data, session):
    """Guarda el producto en la base de datos"""
    try:
        # Crear ml_additional_info
        ml_additional_info = {
            "url": product_data["url"],
            "ml_id": product_data["id"],
            "site": product_data["site_id"]
        }
        
        # Crear objeto Product
        product = Product(
            id=product_data["id"],
            title=product_data["title"],
            price=product_data["price"],
            site_id=product_data["site_id"],
            currency_id=product_data["currency_id"],
            sold_quantity=product_data["sold_quantity"],
            available_quantity=product_data["available_quantity"],
            marca=product_data["marca"],
            modelo=product_data["modelo"],
            caracteristicas=product_data["caracteristicas"],
            ml_additional_info=ml_additional_info
        )
        
        # Verificar si ya existe
        existing = session.query(Product).filter(Product.id == product_data["id"]).first()
        if existing:
            print(f"âš ï¸  Producto {product_data['id']} ya existe en la DB")
            return False
        
        # Guardar
        session.add(product)
        session.commit()
        print(f"âœ… Producto {product_data['id']} guardado en la DB")
        return True
        
    except Exception as e:
        session.rollback()
        print(f"âŒ Error guardando en DB: {e}")
        return False


def extract_product_info(url):
    """
    Extrae informaciÃ³n del producto desde una URL de MercadoLibre
    """
    product_data = {
        "url": url,
        "id": "",
        "title": "",
        "price": 0.0,
        "marca": "",
        "modelo": "",
        "caracteristicas": {},
        "site_id": "MLA",
        "currency_id": "ARS",
        "sold_quantity": 0,
        "available_quantity": 0,
        "extracted_at": datetime.now().isoformat(),
        "success": False,
        "error": ""
    }
    
    try:
        with sync_playwright() as p:
            # Configurar browser con mÃ¡s opciones
            browser = p.chromium.launch(
                headless=True,
                args=['--no-sandbox', '--disable-dev-shm-usage']
            )
            
            # Crear contexto con user agent
            context = browser.new_context(
                user_agent='Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
            )
            
            page = context.new_page()
            
            print(f"ğŸ” Accediendo a: {url}")
            
            # Navegar a la pÃ¡gina
            response = page.goto(url, wait_until="domcontentloaded", timeout=30000)
            
            if response.status != 200:
                product_data["error"] = f"Error HTTP: {response.status}"
                print(f"âŒ Error HTTP: {response.status}")
                return product_data
            
            # Esperar que cargue
            time.sleep(3)
            
            # Verificar si la pÃ¡gina cargÃ³ correctamente
            page_title = page.title()
            print(f"ğŸ“„ TÃ­tulo de pÃ¡gina: '{page_title}'")
            
            if not page_title:
                product_data["error"] = "PÃ¡gina no cargÃ³ correctamente"
                print("âŒ PÃ¡gina no cargÃ³ correctamente")
                return product_data
            
            # Extraer ID del producto desde la URL
            id_match = re.search(r'/p/([A-Z0-9]+)', url)
            if id_match:
                product_data["id"] = id_match.group(1)
                print(f"âœ… ID: {product_data['id']}")
            
            # Extraer tÃ­tulo - mÃ©todo mÃ¡s agresivo
            print("ğŸ“ Buscando tÃ­tulo...")
            
            # Intentar diferentes mÃ©todos para obtener el tÃ­tulo
            title_methods = [
                # MÃ©todo 1: Selectores especÃ­ficos
                lambda: page.locator('h1[data-testid="product-title"]').first.text_content(),
                lambda: page.locator('h1.ui-pdp-title').first.text_content(),
                lambda: page.locator('.ui-pdp-title').first.text_content(),
                lambda: page.locator('[data-testid="product-title"]').first.text_content(),
                
                # MÃ©todo 2: Buscar en todo el HTML
                lambda: page.evaluate('''
                    () => {
                        const selectors = [
                            'h1[data-testid="product-title"]',
                            'h1.ui-pdp-title',
                            '.ui-pdp-title',
                            '[data-testid="product-title"]',
                            'h1'
                        ];
                        for (let selector of selectors) {
                            const el = document.querySelector(selector);
                            if (el && el.textContent && el.textContent.trim().length > 10) {
                                return el.textContent.trim();
                            }
                        }
                        return null;
                    }
                '''),
                
                # MÃ©todo 3: Buscar en meta tags
                lambda: page.evaluate('''
                    () => {
                        const meta = document.querySelector('meta[property="og:title"]');
                        return meta ? meta.getAttribute('content') : null;
                    }
                ''')
            ]
            
            for i, method in enumerate(title_methods, 1):
                try:
                    title = method()
                    if title and title.strip() and len(title.strip()) > 10:
                        product_data["title"] = title.strip()
                        print(f"âœ… TÃ­tulo encontrado (mÃ©todo {i}): {title[:60]}...")
                        break
                    else:
                        print(f"  MÃ©todo {i}: No encontrÃ³ tÃ­tulo vÃ¡lido")
                except Exception as e:
                    print(f"  MÃ©todo {i}: Error - {e}")
            
            # Si no encontramos tÃ­tulo, usar el tÃ­tulo de la pÃ¡gina
            if not product_data["title"] and page_title:
                product_data["title"] = page_title.strip()
                print(f"âš ï¸ Usando tÃ­tulo de pÃ¡gina: {page_title[:60]}...")
            
            # Extraer precio
            print("ğŸ’° Buscando precio...")
            
            price_methods = [
                lambda: page.evaluate('''
                    () => {
                        const selectors = [
                            '.ui-pdp-price .andes-money-amount__fraction',
                            '.ui-pdp-price .andes-money-amount',
                            '.ui-pdp-price',
                            '[data-testid="price"]',
                            '.price-tag-fraction',
                            '.andes-money-amount__fraction'
                        ];
                        for (let selector of selectors) {
                            const el = document.querySelector(selector);
                            if (el && el.textContent) {
                                const text = el.textContent.trim();
                                const numbers = text.replace(/[^\d]/g, '');
                                if (numbers && numbers.length > 2) {
                                    return parseInt(numbers);
                                }
                            }
                        }
                        return 0;
                    }
                ''')
            ]
            
            for i, method in enumerate(price_methods, 1):
                try:
                    price = method()
                    if price and price > 0:
                        product_data["price"] = price
                        print(f"âœ… Precio encontrado: ${price:,.2f}")
                        break
                    else:
                        print(f"  MÃ©todo {i}: No encontrÃ³ precio vÃ¡lido")
                except Exception as e:
                    print(f"  MÃ©todo {i}: Error - {e}")
            
            # Extraer marca y modelo del tÃ­tulo
            if product_data["title"]:
                print("ğŸ·ï¸ Extrayendo marca y modelo...")
                
                # Lista de marcas conocidas
                marcas_conocidas = [
                    'Philco', 'Samsung', 'LG', 'Whirlpool', 'Electrolux', 'BGH', 'Sansei', 
                    'Sanyo', 'Carrier', 'York', 'TCL', 'Hisense', 'Daikin', 'Mitsubishi',
                    'Fujitsu', 'Panasonic', 'Hitachi', 'Toshiba', 'Sharp', 'Sony', 'Bosch',
                    'Mabe', 'Longvie', 'Kohinoor', 'Dream', 'Surrey', 'Siemens', 'GE',
                    'Frigidaire', 'Maytag', 'Amana', 'Kenmore', 'KitchenAid', 'Viking',
                    'Candy', 'Karcher', 'Rowenta', 'Braun', 'Oral-B', 'Philips'
                ]
                
                title_lower = product_data["title"].lower()
                
                # Buscar marca conocida
                for marca in marcas_conocidas:
                    if marca.lower() in title_lower:
                        product_data["marca"] = marca
                        print(f"âœ… Marca: {marca}")
                        
                        # Extraer modelo despuÃ©s de la marca
                        marca_pos = title_lower.find(marca.lower())
                        if marca_pos != -1:
                            after_marca = product_data["title"][marca_pos + len(marca):].strip()
                            modelo_words = after_marca.split()[:4]
                            if modelo_words:
                                product_data["modelo"] = " ".join(modelo_words)
                                print(f"âœ… Modelo: {product_data['modelo']}")
                        break
                
                # Si no se encontrÃ³ marca conocida, usar primera palabra
                if not product_data["marca"]:
                    words = product_data["title"].split()
                    for word in words[:3]:
                        if len(word) >= 3 and word.isalpha() and word[0].isupper():
                            product_data["marca"] = word
                            print(f"âš ï¸ Marca fallback: {word}")
                            break
            
            product_data["success"] = True
            
    except Exception as e:
        product_data["error"] = str(e)
        print(f"âŒ Error general: {e}")
    
    return product_data


def load_urls_from_file(filename="urls.txt"):
    """Carga URLs desde un archivo"""
    urls = []
    try:
        with open(filename, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith('#'):  # Ignorar lÃ­neas vacÃ­as y comentarios
                    urls.append(line)
        print(f"ğŸ“„ Cargadas {len(urls)} URLs desde {filename}")
    except FileNotFoundError:
        print(f"âš ï¸ Archivo {filename} no encontrado")
    except Exception as e:
        print(f"âŒ Error leyendo {filename}: {e}")
    
    return urls


def process_single_url(url):
    """Procesa una sola URL"""
    print(f"\nğŸ” PROCESANDO URL:")
    print("-" * 40)
    print(f"URL: {url}")
    
    product_info = extract_product_info(url)
    
    print(f"\nğŸ“¦ RESULTADO:")
    print(f"âœ… Ã‰xito: {product_info['success']}")
    print(f"ğŸ†” ID: {product_info['id']}")
    print(f"ğŸ“ TÃ­tulo: {product_info['title'][:80]}...")
    print(f"ğŸ’° Precio: ${product_info['price']:,.2f}")
    print(f"ğŸ·ï¸ Marca: {product_info['marca']}")
    print(f"ğŸ”§ Modelo: {product_info['modelo']}")
    
    if product_info['error']:
        print(f"âŒ Error: {product_info['error']}")
    else:
        # Guardar en base de datos
        if product_info['id']:
            session = get_db_session()
            try:
                save_product_to_db(product_info, session)
            finally:
                session.close()
    
    return product_info


def main():
    """FunciÃ³n principal"""
    import sys
    
    # Cargar variables de entorno
    load_env()
    
    print("ğŸš€ Extractor Simple de Productos MercadoLibre")
    print("=" * 60)
    
    # Verificar si se pasÃ³ una URL como parÃ¡metro
    if len(sys.argv) > 1:
        # Modo: URL como parÃ¡metro
        url = sys.argv[1]
        print(f"ğŸ”— Modo: URL como parÃ¡metro")
        print(f"URL: {url}")
        
        product_info = process_single_url(url)
        
    else:
        # Modo: leer desde urls.txt
        print(f"ğŸ“„ Modo: Leer desde urls.txt")
        
        urls = load_urls_from_file("urls.txt")
        
        if not urls:
            print("âŒ No se encontraron URLs para procesar")
            print("\nğŸ’¡ Uso:")
            print("  python extract_product_simple.py                    # Lee desde urls.txt")
            print("  python extract_product_simple.py <URL>              # Procesa una URL especÃ­fica")
            return
        
        print(f"ğŸ”„ Procesando {len(urls)} URLs...")
        
        successful = 0
        failed = 0
        
        for i, url in enumerate(urls, 1):
            print(f"\nğŸ” PRODUCTO {i}/{len(urls)}:")
            print("-" * 40)
            
            product_info = extract_product_info(url)
            
            print(f"\nğŸ“¦ RESULTADO:")
            print(f"âœ… Ã‰xito: {product_info['success']}")
            print(f"ğŸ†” ID: {product_info['id']}")
            print(f"ğŸ“ TÃ­tulo: {product_info['title'][:80]}...")
            print(f"ğŸ’° Precio: ${product_info['price']:,.2f}")
            print(f"ğŸ·ï¸ Marca: {product_info['marca']}")
            print(f"ğŸ”§ Modelo: {product_info['modelo']}")
            
            if product_info['error']:
                print(f"âŒ Error: {product_info['error']}")
                failed += 1
            else:
                # Guardar en base de datos
                if product_info['id']:
                    session = get_db_session()
                    try:
                        if save_product_to_db(product_info, session):
                            successful += 1
                        else:
                            failed += 1
                    finally:
                        session.close()
                else:
                    failed += 1
            
            print()
        
        # Resumen final
        print("=" * 60)
        print(f"ğŸ“Š RESUMEN FINAL:")
        print(f"âœ… Exitosos: {successful}")
        print(f"âŒ Fallidos: {failed}")
        print(f"ğŸ“„ Total procesados: {len(urls)}")


if __name__ == "__main__":
    main()
